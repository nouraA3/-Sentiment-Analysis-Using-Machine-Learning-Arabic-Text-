# -Sentiment-Analysis-Using-Machine-Learning-Arabic-Text-
This project focuses on Sentiment Analysis using Machine Learning (ML) techniques to classify Arabic text into positive, negative, or neutral sentiments. It builds upon previous NLP preprocessing techniques and applies ML models for sentiment prediction.

üìä Overview
With the increasing use of social media platforms, sentiment analysis has become an essential tool for understanding public opinion. This project preprocesses an Arabic tweets dataset and applies TF-IDF vectorization to transform text into numerical features suitable for machine learning classification.

üìÇ Dataset
	‚Ä¢	The dataset consists of Arabic tweets labeled as Positive, Negative, or Neutral.
	‚Ä¢	Preprocessing Steps:
	‚Ä¢	Remove non-Arabic characters, diacritics (Tashkeel), and Tatweel (ŸÄ).
	‚Ä¢	Normalize text and remove stopwords.
	‚Ä¢	Convert text to TF-IDF (Term Frequency-Inverse Document Frequency) features.

 üõ† Methodology

1Ô∏è‚É£ Data Preprocessing
	‚Ä¢	Tokenization & Text Cleaning
	‚Ä¢	Removing Special Characters, Diacritics & Stopwords
	‚Ä¢	TF-IDF Vectorization for Feature Extraction

2Ô∏è‚É£ Machine Learning Model: Random Forest Classifier
	‚Ä¢	Why Random Forest?
	‚Ä¢	Robustness: Reduces overfitting by averaging multiple decision trees.
	‚Ä¢	Scalability: Handles large datasets effectively.
	‚Ä¢	Feature Importance: Identifies key words affecting sentiment classification.

3Ô∏è‚É£ Model Performance
	‚Ä¢	Accuracy: 61.23%
	‚Ä¢	Key Observations:
	‚Ä¢	Neutral sentiment had the highest recall (80%).
	‚Ä¢	Positive sentiment had low recall (4%), meaning the model struggles with positive sentiment detection.
	‚Ä¢	Hyperparameter Tuning:
	‚Ä¢	Initial Parameters: n_estimators=100, max_depth=20 ‚Üí 59% Accuracy
	‚Ä¢	Optimized Parameters: n_estimators=300, max_depth=50 ‚Üí 61% Accuracy


 üì¢ Recommendations for Improvement

To improve sentiment classification accuracy, consider:
‚úÖ Using More Suitable Classifiers:
	‚Ä¢	Logistic Regression (best suited for TF-IDF-based text classification).
	‚Ä¢	Support Vector Machines (SVM) (effective for high-dimensional text data).

‚úÖ Replacing TF-IDF with Word Embeddings:
	‚Ä¢	Word2Vec, FastText, or BERT for better semantic understanding.

‚úÖ Handling Class Imbalance:
	‚Ä¢	Implement class_weight="balanced" in RandomForestClassifier.
	‚Ä¢	Use SMOTE (Synthetic Minority Over-sampling Technique) to improve positive sentiment detection.

‚úÖ Further Hyperparameter Optimization:
	‚Ä¢	Apply GridSearchCV or RandomizedSearchCV to tune model parameters.
